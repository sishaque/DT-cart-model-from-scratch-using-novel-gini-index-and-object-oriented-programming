{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JBHI 10 fold CV",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EzKrX89Kdw"
      },
      "source": [
        "# CART on my dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "import csv\n",
        "from csv import reader\n",
        "\n",
        "\n",
        "from itertools import cycle, islice\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx0wvxdT-WjS"
      },
      "source": [
        "\n",
        "def best_split_point(X, y, column):\n",
        "    # sorting y by values of X makes\n",
        "    # it is almost trivial to count classes\n",
        "    # above or below candidate split point\n",
        "    \n",
        "    # sort X array\n",
        "    ordering = np.argsort(X[:, column])\n",
        "    # classes is y in terms of sorted X array\n",
        "    classes = y[ordering]\n",
        "\n",
        "    # these vectors tell how many of each\n",
        "    # class are present below (to the left)\n",
        "    # of any given candidate splt point\n",
        "    class_0_below = (classes == 0).cumsum()\n",
        "    class_1_below = (classes == 1).cumsum()\n",
        "    # Subtracting the cummulative sum from the total\n",
        "    # gives us the reversed cummulative sum. These\n",
        "    # are how many of each class are above (to the\n",
        "    # right) of any given candidate split point.\n",
        "    #\n",
        "    # Because class_0_below is a cummulative sum\n",
        "    # the last value in the array is the total sum.\n",
        "    # That means we don't need to make another pass\n",
        "    # through the array just to get the total; we can\n",
        "    # just grab the last element. \n",
        "    class_0_above = class_0_below[-1] - class_0_below\n",
        "    class_1_above = class_1_below[-1] - class_1_below\n",
        "    \n",
        "    # below_total = class_0_below + class_1_below\n",
        "    below_total = np.arange(1, len(y)+1)\n",
        "    # above_total = class_0_above + class_1_above\n",
        "    above_total = np.arange(len(y)-1, -1, -1)\n",
        "    # we can now calculate Gini impurity in a single\n",
        "    # vectorized operation. The naive formula would be:\n",
        "    #\n",
        "    #     (class_1_below/below_total)*(class_0_below/below_total)\n",
        "    # \n",
        "    # however, divisions are expensive and we can get this down\n",
        "    # to only one division if we combine the denominator term.\n",
        "     # class left/ total_left + class rigth/total_right\n",
        "    gini = class_1_below * class_0_below / (below_total ** 2) + class_1_above * class_0_above / (above_total ** 2)\n",
        "    \n",
        "    # gini index is nan is 1\n",
        "    gini[np.isnan(gini)] = 1\n",
        "    # we need to reverse the above sorting to\n",
        "    # get the rule into the form C_n < split_value. \n",
        "    best_split_rank = np.argmin(gini)  # minimum gini (0) is the best split rank, correct classification\n",
        "    best_split_gini = gini[best_split_rank] \n",
        "    best_split_index = np.argwhere(ordering == best_split_rank).item(0)\n",
        "    best_split_value = X[best_split_index, column] \n",
        "    \n",
        "    return best_split_gini, best_split_value, column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bqh_ymI-rKV"
      },
      "source": [
        "class Node:\n",
        "    \n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.is_leaf = True\n",
        "        self.column = None\n",
        "        self.split_point = None\n",
        "        self.children = None\n",
        "         \n",
        "    def formatted(self, indent=0):\n",
        "        if self.is_leaf:\n",
        "            s = \"Leaf({p[0]:.3f}, {p[1]:.3f})\".format(p=self.probabilities())\n",
        "        else:\n",
        "            s = \"Branch(X{column} <= {split_point})\\n{left}\\n{right}\".format(\n",
        "                column=self.column, \n",
        "                split_point=self.split_point,\n",
        "                left=self.children[0].formatted(indent+1),\n",
        "                right=self.children[1].formatted(indent+1))\n",
        "        \n",
        "        return \"    \" * indent + s\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.formatted()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self)\n",
        "    \n",
        "    def is_pure(self):\n",
        "        p = self.probabilities()\n",
        "        if p[0] == 1 or p[1] == 1:  # if probability is 1, then it is pure\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def split(self, depth=0):\n",
        "        X, y = self.X, self.y \n",
        "        # if its a leaf node and not pure == 1\n",
        "        if self.is_leaf and not self.is_pure():\n",
        "            splits = [ best_split_point(X, y, column) for column in range(X.shape[1])]  # best split from X\n",
        "            # order splits\n",
        "            splits.sort()\n",
        "            #  best gini, split point and column is from 0 element\n",
        "            gini, split_point, column = splits[0]\n",
        "            # set splits leaf to false\n",
        "            self.is_leaf = False\n",
        "            self.column = column\n",
        "            self.split_point = split_point # left, right split point\n",
        "            below = X[:,column] <= split_point\n",
        "            above = X[:,column] > split_point\n",
        "            # root Node\n",
        "            self.children = [\n",
        "                Node(X[below], y[below]),\n",
        "                Node(X[above], y[above])\n",
        "            ]\n",
        "            # if depth exist, split the child node\n",
        "            if depth:\n",
        "                for child in self.children:\n",
        "                    child.split(depth-1)\n",
        "    \n",
        "    def probabilities(self):\n",
        "    # return array with index of mean of class 0,1\n",
        "        return np.array([\n",
        "            np.mean(self.y == 0),\n",
        "            np.mean(self.y == 1),\n",
        "        ])\n",
        "\n",
        "    def predict_proba(self, row):\n",
        "    # if it is a leaf node retun proabalities \n",
        "        if self.is_leaf:\n",
        "            return self.probabilities()\n",
        "        else:\n",
        "        # if row value is less than split point, return prob of 0/left root node, otherwise its the right\n",
        "            if row[self.column] <= self.split_point:\n",
        "                return self.children[0].predict_proba(row)\n",
        "            else:\n",
        "                return self.children[1].predict_proba(row)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pDj4_JC-wSQ"
      },
      "source": [
        "class Decision_TreeClassifier:\n",
        "    # initialize max_depth\n",
        "    def __init__(self, max_depth = 3):\n",
        "        # initialize max depth as integer\n",
        "        self.max_depth = int(max_depth)\n",
        "        # no root node\n",
        "        self.root = None\n",
        "        \n",
        "    # fit the model\n",
        "    def fit(self, X, y):\n",
        "        # define root Node\n",
        "        self.root = Node(X, y)\n",
        "        self.root.split(self.max_depth)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        results = [] # initialize empty array\n",
        "        for row in X:\n",
        "            p = self.root.predict_proba(row)  # return predict value 1 using root node\n",
        "            # add p list to results\n",
        "            results += [p]\n",
        "        # return the list of results\n",
        "        return np.array(results)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # probabilities above 0.5 are int type\n",
        "        return (self.predict_proba(X)[:, 1] > 0.5).astype(int)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6dXO80g-0gQ"
      },
      "source": [
        "filename = \"/content/stress_analysis.csv\"\n",
        "names = ['Mean HR','SDNN','RMSSD','NN50','PNN50','SD1','SD2','ApEn',\n",
        "         'VLF(ms^2)','LF(ms^2)','HF(ms^2)','LF/HF ratio','TP',\n",
        "         'VLF_lomb(ms^2)','LF_lomb(ms^2)','HF_lomb(ms^2)','LF/HF_lomb ratio','TP_lomb','Stress']\n",
        "dataframe = read_csv(filename, names =names)\n",
        "df = dataframe\n",
        "df.head(5)\n",
        "# df.drop(['Mean HR','SDNN','RMSSD','PNN50','SD1','SD2','ApEn','VLF(ms^2)','LF(ms^2)','HF(ms^2)','TP','LF_lomb(ms^2)','VLF_lomb(ms^2)','LF/HF_lomb ratio','TP_lomb'], axis = 1, inplace = True)\n",
        "array = dataframe.values\n",
        "X = np.array(dataframe.iloc[:,0:18])\n",
        "y = np.array(dataframe.iloc[:,18])\n",
        "y=y.reshape(-1,1)\n",
        "# scaler = MinMaxScaler(feature_range = (0,1)) # scale the values to min 0, max 1\n",
        "# rescaledX = scaler.fit_transform(X) # fit the trainning feature X into scaler\n",
        "# # #summarize the transformed data\n",
        "\n",
        "# scaler = MinMaxScaler(feature_range = (0,1)) # scale the values to min 0, max 1\n",
        "# rescaled_y = scaler.fit_transform(y)\n",
        "# set_printoptions(precision=3) # how many decimal places.\n",
        "# print(rescaledX[0:5,:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OenvUkwy_NSw",
        "outputId": "1cfd5c0f-af7f-4504-831e-47b77668cee1"
      },
      "source": [
        "dt = DecisionTreeClassifier(max_depth = 2)\n",
        "dt.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSjRpP83_SqY",
        "outputId": "23ad7331-0288-49a1-bb79-32420ad795bf"
      },
      "source": [
        "model = Decision_TreeClassifier(max_depth=2)\n",
        "model.fit(X, y)\n",
        "y_hat = model.predict(X)\n",
        "p_hat = model.predict_proba(X)[:,1]\n",
        "\n",
        "print(confusion_matrix(y, y_hat))\n",
        "print('Acc:', accuracy_score(y, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[28  0]\n",
            " [ 6 15]]\n",
            "Acc: 0.8775510204081632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3EhUjvI_WRq"
      },
      "source": [
        "def classify(model, Iterations, num_folds, rescaledX, y):\n",
        "    acc = []\n",
        "    pre = []\n",
        "    rec = []\n",
        "\n",
        "    for i in range(Iterations):\n",
        "\n",
        "        # Shuffle the dataset for each iteration\n",
        "        data = list(zip(rescaledX,y))\n",
        "        random.shuffle(data)\n",
        "        rescaledX, y = zip(*data)\n",
        "        rescaledX = np.array(rescaledX)\n",
        "        y = np.array(y)\n",
        "        #y = y.reshape(-1,1)\n",
        "\n",
        "        # Perform 5-fold validation\n",
        "        kfold = KFold(n_splits = num_folds)#, shuffle=True, random_state = None)\n",
        "        #results = cross_val_score(DT, rescaledX, y, cv = kfold)\n",
        "        #print(results)\n",
        "\n",
        "        for train_index, test_index in kfold.split(rescaledX):\n",
        "            X_train, X_test = rescaledX[train_index], rescaledX[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            # perform training and testing\n",
        "            if model == SVC:\n",
        "                model.fit(X_train,y_train)\n",
        "            else:\n",
        "                model.fit(X_train,y_train.ravel())\n",
        "            #dtscores = DT.score(X_test,y_test)\n",
        "            yPred = model.predict(X_test)\n",
        "\n",
        "\n",
        "            # record performance\n",
        "            acc = np.append(acc,metrics.accuracy_score(y_test, yPred)) \n",
        "            pre = np.append(pre,metrics.precision_score(y_test, yPred, pos_label=1, average='macro'))\n",
        "            rec = np.append(rec,metrics.recall_score(y_test, yPred, pos_label=1, average='macro'))\n",
        "\n",
        "    return acc, pre, rec\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYA4M4bt_gc8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import set_printoptions\n",
        "\n",
        "# Preparing dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random\n",
        "\n",
        "# Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Performance Measure\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn import metrics\n",
        "import statistics\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# Gradient Boost\n",
        "GB = GradientBoostingClassifier(n_estimators=100, \n",
        "                                learning_rate=1.0, \n",
        "                                max_depth=1, \n",
        "                                random_state=0)\n",
        "\n",
        "# Support Vector Machine\n",
        "SVM = SVC(random_state = 0, gamma='scale',probability = True)\n",
        "\n",
        "# Linear Discrimant Analysis\n",
        "LDA = LinearDiscriminantAnalysis()\n",
        "\n",
        "NB = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Hos9GE_qVb",
        "outputId": "be25ad73-3b2b-4e03-cf86-4586960095ef"
      },
      "source": [
        "acc, pre, rec = classify(GB, 1, 10,  X, y)\n",
        "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
        "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
        "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (mean, std): 0.8150000000000001 0.17646214576755234\n",
            "Precision (mean, std): 0.8333333333333333 0.19543398999264291\n",
            "Recall (mean, std): 0.8041666666666667 0.19543398999264291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qekJHh0HPp09",
        "outputId": "fdc04b67-61ad-49a8-f2d5-39fe67dd1a31"
      },
      "source": [
        "NB.fit(X, y)\n",
        "y_hat = NB.predict(X)\n",
        "p_hat = NB.predict_proba(X)[:,1]\n",
        "\n",
        "print(classification_report(y, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.93      0.73        28\n",
            "         1.0       0.67      0.19      0.30        21\n",
            "\n",
            "    accuracy                           0.61        49\n",
            "   macro avg       0.64      0.56      0.51        49\n",
            "weighted avg       0.63      0.61      0.55        49\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j22ulajpABy1",
        "outputId": "cf37d5b7-6518-4f79-8463-f89c5659c6cf"
      },
      "source": [
        "acc, pre, rec = classify(SVM, 1, 1,  X, y)\n",
        "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
        "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
        "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (mean, std): 0.555 0.2753280871170894\n",
            "Precision (mean, std): 0.33 0.25975415727611023\n",
            "Recall (mean, std): 0.525 0.25975415727611023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LybWjU-mAHfp",
        "outputId": "ce6a8507-71ce-4413-a134-2e403e40520c"
      },
      "source": [
        "acc, pre, rec = classify(NB, 1, 1,  X, y)\n",
        "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
        "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
        "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (mean, std): 0.5650000000000001 0.2728959915832811\n",
            "Precision (mean, std): 0.4325 0.31070037370788955\n",
            "Recall (mean, std): 0.5175 0.31070037370788955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PetogNFATc_",
        "outputId": "ba6db9dc-6d59-4451-a2ba-9899795f5317"
      },
      "source": [
        "# personalized model\n",
        "\n",
        "acc, pre, rec = classify(model, 1, 1,  X, y)\n",
        "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
        "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
        "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (mean, std): 0.65 0.14337208778404378\n",
            "Precision (mean, std): 0.6833333333333333 0.16220890356284925\n",
            "Recall (mean, std): 0.6833333333333333 0.16220890356284925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}